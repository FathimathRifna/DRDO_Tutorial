{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKsHNYBIrxbp"
   },
   "source": [
    "# RNN Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks (RNNs) are a class of neural networks that are naturally suited to processing time-series data and other sequential data. The distinctive feature of RNNs is their ability to send information over time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we deep dive into the details of what a recurrent neural network is, let’s ponder a bit on if we really need a network specially for dealing with sequences in information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usecase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment Classification** – This can be a task of simply classifying tweets into positive and negative sentiment. Importantly, here the input would be a tweet of varying lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language Translation** - Language model is one of the most interesting topics that usesequence labeling. There is a need to understand the meaning of each word, and the relationship between words while performing translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Captioning** - Generating textual description of an image. Often involves varying length, coherent outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Music Generation** - Music is temporal, and hence cannot be generated using normal neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN provide flexibility by being able to handle sequential data of varying length (both in input and output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far. In theory, RNNs can make use of information in arbitrarily long sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN works on the principle of saving the output of a particular layer and feeding this back to the input in order to predict the output of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN](https://www.simplilearn.com/ice9/free_resources_article_thumb/Simple_Recurrent_Neural_Network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN Unrolled**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN Structure](https://www.simplilearn.com/ice9/free_resources_article_thumb/Fully_connected_Recurrent_Neural_Network.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each time step, $t$, let $x^{t}$ denote the input, $y^{t}$ denote the output and the hidden state be denoted by $h^{t}$. Following addition over normal neural network must be noted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h^{t} = f_{1}(h_{t-1},x_{t})$$\n",
    "$$h^{t} = f_{2}(h_{t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The coefficients remains constant thorugh temporal space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation through time is when we apply a Backpropagation algorithm to a Recurrent Neural network that has time series data as its input. A RNN essentially processes sequences one step at a time, so during backpropagation the gradients flow backward across time steps. So, the gradient wrt the hidden state and the gradient from the previous time step are used. we can use the chain rule to compute the gradients recursively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types and Applications of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One to one RNN**: Traditional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![One-to-One](https://www.simplilearn.com/ice9/free_resources_article_thumb/One_to_One_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One to many RNN**: Generative Tasks, like music generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![one-to-many](https://www.simplilearn.com/ice9/free_resources_article_thumb/One_to_Many_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Many to One**: Classification tasks, sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![many-to-one](https://www.simplilearn.com/ice9/free_resources_article_thumb/Many_to_One_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Many to Many**: Machine translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![many-to-many](https://www.simplilearn.com/ice9/free_resources_article_thumb/Many_to_Many_RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T23wJIC5Jnc5"
   },
   "source": [
    "**Checking system and library version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFAeE1ziq3WV",
    "outputId": "721fda2e-41ee-48cf-aafc-3a99ee8adcf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your python version: 3\n",
      "Your pytorch version: 1.12.1+cu116\n",
      "GPU being used: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import math\n",
    "print('Your python version: {}'.format(sys.version_info.major))\n",
    "print('Your pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU being used: {}'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIBahnmtJ4WP"
   },
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_LFajsHbOzCY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-UZFTjRKEz_"
   },
   "source": [
    "**Mounting drive and fetching dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t9UhHNoCIxPy",
    "outputId": "122b9b36-760e-49f7-cf78-406f65b35f0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>174.68</td>\n",
       "      <td>175.42</td>\n",
       "      <td>174.50</td>\n",
       "      <td>175.01</td>\n",
       "      <td>16349444</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>170.80</td>\n",
       "      <td>171.47</td>\n",
       "      <td>169.68</td>\n",
       "      <td>170.57</td>\n",
       "      <td>33185536</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>170.10</td>\n",
       "      <td>170.78</td>\n",
       "      <td>169.71</td>\n",
       "      <td>170.60</td>\n",
       "      <td>21498213</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>171.00</td>\n",
       "      <td>171.85</td>\n",
       "      <td>170.48</td>\n",
       "      <td>171.08</td>\n",
       "      <td>16480187</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>170.52</td>\n",
       "      <td>170.59</td>\n",
       "      <td>169.22</td>\n",
       "      <td>169.23</td>\n",
       "      <td>25999922</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close    Volume  Name\n",
       "3014  2017-12-22  174.68  175.42  174.50  175.01  16349444  AAPL\n",
       "3015  2017-12-26  170.80  171.47  169.68  170.57  33185536  AAPL\n",
       "3016  2017-12-27  170.10  170.78  169.71  170.60  21498213  AAPL\n",
       "3017  2017-12-28  171.00  171.85  170.48  171.08  16480187  AAPL\n",
       "3018  2017-12-29  170.52  170.59  169.22  169.23  25999922  AAPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Apple.csv')\n",
    "data.sort_values('Date')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwVR2fMztv85"
   },
   "source": [
    "**Price Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8gU-Fd4SuyNj"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "gam9b3xit0J_",
    "outputId": "d5011cc8-f065-44de-8998-ce95f5ebc6ac"
   },
   "outputs": [],
   "source": [
    "fig = px.line(data, x='Date', y=\"Close\")\n",
    "fig.write_image(\"./fig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy9iqjJ5vDCl"
   },
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g_0vVbkcvK8T"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SHlzCLft3Mw",
    "outputId": "195320bc-7d6e-4f5f-b263-26b1364248f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6831/1016894062.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price = data[['Close']]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "price.loc[:,('Close')] = scaler.fit_transform(price.loc[:,('Close')].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBWQvLTTxcMY"
   },
   "source": [
    "**Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GoqbaXJ4xfQd"
   },
   "outputs": [],
   "source": [
    "def split_data(stock, lookback):\n",
    "    data_raw = stock.to_numpy() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    # 80:20 train-test split\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLIYLtAMxmbW",
    "outputId": "eb2e2398-cc84-4264-9230-1b6c03df02cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  (2399, 19, 1)\n",
      "y_train.shape =  (2399, 1)\n",
      "x_test.shape =  (600, 19, 1)\n",
      "y_test.shape =  (600, 1)\n"
     ]
    }
   ],
   "source": [
    "lookback = 20 # choose sequence length\n",
    "x_train, y_train, x_test, y_test = split_data(price, lookback)\n",
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "73pxUmooyGzZ"
   },
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "# y_train_gru = torch.from_numpy(y_train)\n",
    "# y_test_gru = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH0NOi06x5IZ"
   },
   "source": [
    "**Setting Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n2hZqhI-yQOk"
   },
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEMI-IufygsK"
   },
   "source": [
    "**Definig Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "W8uf-js5yjwy"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w07K3-jyrqp"
   },
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cn6-33fuyqmz"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=input_dim, output_size=output_dim, hidden_dim=hidden_dim, n_layers=num_layers)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "# model = model.to('cuda')\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "CNmkYm73zMC9",
    "outputId": "c4c1d05c-974c-4df9-b0d4-f1c4824397ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.21268369257450104\n",
      "Epoch  1 MSE:  0.3244333863258362\n",
      "Epoch  2 MSE:  0.10748942196369171\n",
      "Epoch  3 MSE:  0.12962789833545685\n",
      "Epoch  4 MSE:  0.11968861520290375\n",
      "Epoch  5 MSE:  0.06839635968208313\n",
      "Epoch  6 MSE:  0.03909873589873314\n",
      "Epoch  7 MSE:  0.05175027251243591\n",
      "Epoch  8 MSE:  0.00859392061829567\n",
      "Epoch  9 MSE:  0.012289724312722683\n",
      "Epoch  10 MSE:  0.027167055755853653\n",
      "Epoch  11 MSE:  0.014639001339673996\n",
      "Epoch  12 MSE:  0.012984096072614193\n",
      "Epoch  13 MSE:  0.008481314405798912\n",
      "Epoch  14 MSE:  0.0020878964569419622\n",
      "Epoch  15 MSE:  0.007266161032021046\n",
      "Epoch  16 MSE:  0.012589436024427414\n",
      "Epoch  17 MSE:  0.011321603320538998\n",
      "Epoch  18 MSE:  0.007503440137952566\n",
      "Epoch  19 MSE:  0.006073433440178633\n",
      "Epoch  20 MSE:  0.005117951892316341\n",
      "Epoch  21 MSE:  0.001966249430552125\n",
      "Epoch  22 MSE:  0.0007680241833440959\n",
      "Epoch  23 MSE:  0.003276276867836714\n",
      "Epoch  24 MSE:  0.005111099220812321\n",
      "Epoch  25 MSE:  0.004182235337793827\n",
      "Epoch  26 MSE:  0.003088510362431407\n",
      "Epoch  27 MSE:  0.0028374087996780872\n",
      "Epoch  28 MSE:  0.0016896520974114537\n",
      "Epoch  29 MSE:  0.0005542932194657624\n",
      "Epoch  30 MSE:  0.000987543840892613\n",
      "Epoch  31 MSE:  0.0019800011068582535\n",
      "Epoch  32 MSE:  0.0022153155878186226\n",
      "Epoch  33 MSE:  0.0019382822792977095\n",
      "Epoch  34 MSE:  0.0018692187732085586\n",
      "Epoch  35 MSE:  0.00174034689553082\n",
      "Epoch  36 MSE:  0.0010812042746692896\n",
      "Epoch  37 MSE:  0.0004979455261491239\n",
      "Epoch  38 MSE:  0.0005808998830616474\n",
      "Epoch  39 MSE:  0.0008702161139808595\n",
      "Epoch  40 MSE:  0.0009160484769381583\n",
      "Epoch  41 MSE:  0.000989092281088233\n",
      "Epoch  42 MSE:  0.0011416285997256637\n",
      "Epoch  43 MSE:  0.0009470349759794772\n",
      "Epoch  44 MSE:  0.000564982183277607\n",
      "Epoch  45 MSE:  0.00045432394836097956\n",
      "Epoch  46 MSE:  0.0005034048808738589\n",
      "Epoch  47 MSE:  0.000491721264552325\n",
      "Epoch  48 MSE:  0.0005383118987083435\n",
      "Epoch  49 MSE:  0.0006783488788641989\n",
      "Epoch  50 MSE:  0.0006872019730508327\n",
      "Epoch  51 MSE:  0.000546580646187067\n",
      "Epoch  52 MSE:  0.00045824298285879195\n",
      "Epoch  53 MSE:  0.00042566770571283996\n",
      "Epoch  54 MSE:  0.00035872648004442453\n",
      "Epoch  55 MSE:  0.00034356286050751805\n",
      "Epoch  56 MSE:  0.00042695828597061336\n",
      "Epoch  57 MSE:  0.000465127028292045\n",
      "Epoch  58 MSE:  0.0004270262725185603\n",
      "Epoch  59 MSE:  0.00040739704854786396\n",
      "Epoch  60 MSE:  0.00037924444768577814\n",
      "Epoch  61 MSE:  0.0003175702877342701\n",
      "Epoch  62 MSE:  0.0003028109495062381\n",
      "Epoch  63 MSE:  0.00033631111728027463\n",
      "Epoch  64 MSE:  0.0003447855997364968\n",
      "Epoch  65 MSE:  0.0003422973386477679\n",
      "Epoch  66 MSE:  0.00035182610736228526\n",
      "Epoch  67 MSE:  0.0003339409304317087\n",
      "Epoch  68 MSE:  0.0002976041578222066\n",
      "Epoch  69 MSE:  0.00028937961906194687\n",
      "Epoch  70 MSE:  0.0002928089234046638\n",
      "Epoch  71 MSE:  0.0002886097936425358\n",
      "Epoch  72 MSE:  0.0002982296282425523\n",
      "Epoch  73 MSE:  0.00030693408916704357\n",
      "Epoch  74 MSE:  0.00029322082991711795\n",
      "Epoch  75 MSE:  0.0002807741693686694\n",
      "Epoch  76 MSE:  0.0002768257400020957\n",
      "Epoch  77 MSE:  0.0002681230253074318\n",
      "Epoch  78 MSE:  0.00026724973577074707\n",
      "Epoch  79 MSE:  0.0002753543376456946\n",
      "Epoch  80 MSE:  0.0002746058162301779\n",
      "Epoch  81 MSE:  0.00026986494776792824\n",
      "Epoch  82 MSE:  0.00026773562422022223\n",
      "Epoch  83 MSE:  0.000260571192484349\n",
      "Epoch  84 MSE:  0.00025493407156318426\n",
      "Epoch  85 MSE:  0.0002569012576714158\n",
      "Epoch  86 MSE:  0.0002572771336417645\n",
      "Epoch  87 MSE:  0.00025633888435550034\n",
      "Epoch  88 MSE:  0.0002569126372691244\n",
      "Epoch  89 MSE:  0.0002532106591388583\n",
      "Epoch  90 MSE:  0.00024864973966032267\n",
      "Epoch  91 MSE:  0.0002477163216099143\n",
      "Epoch  92 MSE:  0.0002463956770952791\n",
      "Epoch  93 MSE:  0.00024581284378655255\n",
      "Epoch  94 MSE:  0.00024678107001818717\n",
      "Epoch  95 MSE:  0.00024517838028259575\n",
      "Epoch  96 MSE:  0.00024281590594910085\n",
      "Epoch  97 MSE:  0.00024150090757757425\n",
      "Epoch  98 MSE:  0.00023947509180288762\n",
      "Epoch  99 MSE:  0.00023860321380198002\n"
     ]
    }
   ],
   "source": [
    "# Step through epochs\n",
    "hist = np.zeros(num_epochs)\n",
    "for t in range(num_epochs):\n",
    "  y_train_pred = model(x_train.float())[0]\n",
    "  loss = criterion(y_train_pred, y_train)\n",
    "  print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "  hist[t] = loss.item()\n",
    "  optimiser.zero_grad()\n",
    "  loss.backward()\n",
    "  optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcOSHz7Fz-oB"
   },
   "source": [
    "**Training Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "57nVLlYD0CKh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.363832</td>\n",
       "      <td>10.790002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.602504</td>\n",
       "      <td>10.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.719219</td>\n",
       "      <td>10.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.459437</td>\n",
       "      <td>10.260001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.206417</td>\n",
       "      <td>9.610002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>113.534836</td>\n",
       "      <td>115.129997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>113.726974</td>\n",
       "      <td>115.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>115.190041</td>\n",
       "      <td>119.719994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>119.292183</td>\n",
       "      <td>113.490005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>117.691666</td>\n",
       "      <td>115.239998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         predict    original\n",
       "0      11.363832   10.790002\n",
       "1      11.602504   10.770000\n",
       "2      11.719219   10.299999\n",
       "3      11.459437   10.260001\n",
       "4      11.206417    9.610002\n",
       "...          ...         ...\n",
       "2394  113.534836  115.129997\n",
       "2395  113.726974  115.519997\n",
       "2396  115.190041  119.719994\n",
       "2397  119.292183  113.490005\n",
       "2398  117.691666  115.239998\n",
       "\n",
       "[2399 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pd.DataFrame(scaler.inverse_transform(y_train_pred.detach().numpy()),columns=['predict'])\n",
    "original = pd.DataFrame(scaler.inverse_transform(y_train.detach().numpy()),columns=['original'])\n",
    "combined = pd.concat([predict,original],axis=1)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(combined, x=combined.index, y=[\"predict\",\"original\"])\n",
    "fig.write_image(\"./fig2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.31 RMSE\n",
      "Test Score: 3.16 RMSE\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model(x_test)[0]\n",
    "\n",
    "\n",
    "# invert predictions\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n",
    "y_train = scaler.inverse_transform(y_train.detach().numpy())\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test.detach().numpy())\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example RNN seems to do extremly well, but given the nature of training/testing, it is safe to say we greatly overfit. This implementation, as intended, highlights the benefits of a RNN, but would fail to generalise well. Let's look at why by going over limitations faced by RNN architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two common problems that occur during the backpropagation of time-series data are the vanishing and exploding gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Explosion**: In some cases, the gradients keep on getting larger and larger as the backpropagation algorithm progresses. This, in turn, causes very large weight updates and causes the gradient descent to diverge. This is known as the exploding gradients problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanishing Gradient**: On the other hand, as the backpropagation algorithm advances downwards(or backward) from the output layer towards the input layer, the gradients might get smaller and smaller and approach zero which eventually leaves the weights of the initial or lower layers nearly unchanged. As a result, the gradient descent never converges to the optimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem faced by RNN architecture is the lack of **parallelization**. RNNs require the output of the previous node to do the computation over the present node. Due to this connection, RNNs are not suitable for parallelizing or stacking up with other models. The overall computational expense that goes on can seldom be justified with any accuracy gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite difficult to train RNNs on too long sequences, given the problems discussed above,especially while using ReLU or tanh activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Clipping**: It is a technique used to cope with the exploding gradient problem sometimes encountered when performing backpropagation. By capping the maximum value for the gradient, the phenomenon is controlled in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gated Cells**: While not going to much detail, the underlying idea here is to **selectively** add/remove information with each recurrent unit. LSTMs (Long Short Term Memory) and GRUs are some popular examples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**: Key concepts:\n",
    "\n",
    "1. Maintain a cell state.\n",
    "2. Use gate to control flow of information;\n",
    "    a.  Forget gate gets rid of irrelevant information.\n",
    "    b. Store relevant information from current input.\n",
    "    c. Selectively update cell state.\n",
    "    d. Output gate returns a filtered cell state.\n",
    "3.  Backprop through time with partially uniterrupted gradient flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these solve some of our gradient problems, we still haven't solved the problem of complex and non-parallizable calculations. This is where mechasims like attention come in. But more on that in upcoming tutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a text generation model imitating the style of your favorite author. See how far you can push it, it your network able to generate coherent words, phrases, sentences, paragraphs? Is the stylistic flair being carried over? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to consider -\n",
    "1. Training data (take a corpus of literature by the author)\n",
    "2. Encoding (letter/word level encoding, one-hot encodings/encoding based on seniment)\n",
    "3. Loss metric\n",
    "4. Input for the trained model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
